[{"authors":null,"categories":null,"content":"I am a second year DPhil (PhD) student in the Department of Engineering Science at the University of Oxford, advised by Professor Philip Torr in the Torr Vision Group and Professor Yarin Gal in Oxford Applied and Theoretical Machine Learning Group. I obtained my Bachelor of Engineering degree in Computer Science and Engineering from Jadavpur University, Kolkata, India and completed my Master of Science (MSc) in Computer Science from the University of Oxford.\nMy current research focuses on uncertainty quantification in deep neural networks using Bayesian and non-Bayesian approaches in a scalable, computationally light-weight manner with applications in Computer Vision and Natural Language Processing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1605655129,"objectID":"811377bf92f903587e3a297d8ba68a5c","permalink":"https://omegafragger.github.io/author/jishnu-mukhoti/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jishnu-mukhoti/","section":"authors","summary":"I am a second year DPhil (PhD) student in the Department of Engineering Science at the University of Oxford, advised by Professor Philip Torr in the Torr Vision Group and Professor Yarin Gal in Oxford Applied and Theoretical Machine Learning Group.","tags":null,"title":"Jishnu Mukhoti","type":"authors"},{"authors":["jishnu mukhoti, viveka kulharia, amartya sanyal, stuart golodetz, philip h.s. torr","puneet k. dokania"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605655129,"objectID":"a39b2169be5d3780a5da3ca440540e62","permalink":"https://omegafragger.github.io/publication/calibration_neurips_2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/calibration_neurips_2020/","section":"publication","summary":"Propose focal loss as an alternative to cross-entropy loss for training well-calibrated, confident and accurate neural networks.","tags":["source themes"],"title":"Calibrating Deep Neural Networks using Focal Loss","type":"publication"},{"authors":["jishnu mukhoti, viveka kulharia, amartya sanyal, stuart golodetz, philip h.s. torr","puneet k. dokania"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605655129,"objectID":"420c1653e1997adfa9fc4129d1539c47","permalink":"https://omegafragger.github.io/publication/calibration_icml_udl_2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/calibration_icml_udl_2020/","section":"publication","summary":"Propose focal loss as an alternative to cross-entropy loss for training well-calibrated, confident and accurate neural networks.","tags":["source themes"],"title":"On using Focal Loss for Neural Network Calibration","type":"publication"},{"authors":["jishnu mukhoti"],"categories":null,"content":"","date":1595003700,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605655129,"objectID":"65d5b982ecf26174f76a0a9f0e2a2168","permalink":"https://omegafragger.github.io/talk/icml_udl/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/icml_udl/","section":"talk","summary":"Spotlight Talk at the ICML 2020, Workshop on Uncertainty and Robustness in Deep Learning","tags":[],"title":"On using Focal Loss for Neural Network Calibration","type":"talk"},{"authors":["jishnu mukhoti","yarin gal"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1553299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605655129,"objectID":"997383ea191ff309731648a211864a03","permalink":"https://omegafragger.github.io/publication/bdl_semseg_2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/bdl_semseg_2018/","section":"publication","summary":"We propose new metrics to evaluate uncertainty estimates in semantic segmentation, evaluate Bayesian Deep Learning methods using these metrics and hence, create new benchmarks.","tags":["source themes"],"title":"Evaluating Bayesian Deep Learning Methods for Semantic Segmentation","type":"publication"},{"authors":["jishnu mukhoti","pontus stenetorp, yarin gal"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1544140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605655129,"objectID":"a8fd3daedb949fb02a880b27437acdde","permalink":"https://omegafragger.github.io/publication/bdl_workshop_2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/bdl_workshop_2018/","section":"publication","summary":"We re-evaluate MC Dropout by performing grid-search over dropout rates to generate significantly stronger baselines and compare MC Dropout with other state-of-the-art VI approaches.","tags":["source themes"],"title":"On the Importance of Strong Baselines in Bayesian Deep Learning","type":"publication"}]